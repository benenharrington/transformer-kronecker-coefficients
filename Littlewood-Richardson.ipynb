{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import KroneckerModel\n",
    "import sys  \n",
    "sys.path.insert(0, '../symchar')\n",
    "from symchar import Partition, character_table\n",
    "from math import factorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_partition(mu, nu):\n",
    "    return Partition(sorted(mu + nu, reverse=True))\n",
    "\n",
    "def get_lr_coefficient(i_table, j_table, k_table, lambda_partition, mu_partition, nu_partition):\n",
    "    i_character = i_table.get_character(lambda_partition)\n",
    "    j_character = j_table.get_character(mu_partition)\n",
    "    k_character = k_table.get_character(nu_partition)\n",
    "    cumulative_dot_product = 0\n",
    "    for j_class, j_class_index in j_table.partition_lookup.items():\n",
    "        for k_class, k_class_index in k_table.partition_lookup.items():\n",
    "            i_class = join_partition(j_class, k_class)\n",
    "            i_class_index = i_table.partition_lookup[i_class]\n",
    "            cumulative_dot_product += j_table.conjugacy_class_sizes[j_class_index]*k_table.conjugacy_class_sizes[k_class_index]*i_character[i_class_index]*j_character[j_class_index]*k_character[k_class_index]\n",
    "    return cumulative_dot_product // (factorial(j_table.group_number)*factorial(k_table.group_number))\n",
    "\n",
    "def write_data_for_character_table_i(i, character_table_dict, f):\n",
    "    i_table = character_table_dict[i]\n",
    "    for lambda_partition in i_table.partition_lookup:\n",
    "        for j in range(1, i):\n",
    "            j_table = character_table_dict[j]\n",
    "            k = i - j\n",
    "            k_table = character_table_dict[k]\n",
    "            for mu_partition in j_table.partition_lookup:\n",
    "                for nu_partition in k_table.partition_lookup:\n",
    "                    lr_coefficient = get_lr_coefficient(i_table, j_table, k_table, lambda_partition, mu_partition, nu_partition)\n",
    "                    if lr_coefficient > 0: \n",
    "                        f.write(' '.join([str(part) for part in lambda_partition]) + '  ' + ' '.join([str(part) for part in mu_partition]) + '  ' + ' '.join([str(part) for part in nu_partition]) + '  1\\n')\n",
    "                    else:\n",
    "                        f.write(' '.join([str(part) for part in lambda_partition]) + '  ' + ' '.join([str(part) for part in mu_partition]) + '  ' + ' '.join([str(part) for part in nu_partition]) + '  0\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_groups = [i for i in range(3, 16, 2)]\n",
    "training_groups = [1] + [i for i in range(2, 16, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting character tables\n",
      "1\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "3\n",
      "5\n",
      "7\n",
      "9\n",
      "11\n",
      "13\n",
      "15\n",
      "Preparing training data\n",
      "1\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "Preparing validation data\n",
      "3\n",
      "5\n",
      "7\n",
      "9\n",
      "11\n",
      "13\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "character_table_dict = {}\n",
    "print(\"Getting character tables\")\n",
    "for i in training_groups + validation_groups:\n",
    "    print(i)\n",
    "    character_table_dict[i] = character_table(i)\n",
    "\n",
    "print(\"Preparing training data\")\n",
    "with open('lr_training_data.txt', 'w') as f:\n",
    "    for i in training_groups:\n",
    "        print(i)\n",
    "        write_data_for_character_table_i(i, character_table_dict, f)\n",
    "        \n",
    "print(\"Preparing validation data\")\n",
    "with open('lr_validation_data.txt', 'w') as f:\n",
    "    for i in validation_groups:\n",
    "        print(i)\n",
    "        write_data_for_character_table_i(i, character_table_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PARTITION_LENGTH = 10\n",
    "MAX_INPUT_LENGTH = 3*MAX_PARTITION_LENGTH\n",
    "MAX_PART_VALUE = 12\n",
    "\n",
    "def line_to_data(line):\n",
    "    partition_1, partition_2, partition_3, ground_truth = line.split('  ')\n",
    "    partition_1, partition_2, partition_3 = [[int(item)-1 for item in partition.split(' ')] for partition in [partition_1, partition_2, partition_3]]\n",
    "    lengths = [len(partition) for partition in [partition_1, partition_2, partition_3]]\n",
    "    if any(length > 10 for length in lengths) or any(value >= MAX_PART_VALUE for value in [partition_1[0], partition_2[0], partition_3[0]]):\n",
    "        return [None]*5\n",
    "    total_lengths = sum(lengths)\n",
    "    mask = [1]*total_lengths + [0]*(MAX_INPUT_LENGTH - total_lengths)\n",
    "    sequence_positions = lengths[0]*[1] + lengths[1]*[2] + lengths[2]*[3] + [0]*(MAX_INPUT_LENGTH - total_lengths)\n",
    "    term_positions = [i for i in range(0, lengths[0])] + [i for i in range(0, lengths[1])] + [i for i in range(0, lengths[2])] + [0]*(MAX_INPUT_LENGTH - total_lengths)\n",
    "    partition_data = partition_1 + partition_2 + partition_3 + [0]*(MAX_INPUT_LENGTH - total_lengths)\n",
    "    ground_truth = int(ground_truth[0])\n",
    "    return partition_data, sequence_positions, term_positions, ground_truth, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with open('lr_training_data.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "all_partition_data, all_sequence_positions, all_term_positions, all_ground_truths, all_masks = [], [], [], [], []\n",
    "for line in lines:\n",
    "    partition_data, sequence_positions, term_positions, ground_truth, mask = line_to_data(line)\n",
    "    if partition_data is not None:\n",
    "        all_partition_data.append(partition_data)\n",
    "        all_sequence_positions.append(sequence_positions)\n",
    "        all_term_positions.append(term_positions)\n",
    "        all_ground_truths.append(ground_truth)\n",
    "        all_masks.append(mask)\n",
    "        \n",
    "import torch\n",
    "x_partition_data = torch.tensor(all_partition_data)\n",
    "x_sequence_positions = torch.tensor(all_sequence_positions)\n",
    "x_term_positions = torch.tensor(all_term_positions)\n",
    "x_masks = torch.tensor(all_masks, dtype=float)\n",
    "y_data = torch.tensor(all_ground_truths)\n",
    "TRAIN_SIZE = len(y_data)\n",
    "train_shuffle = np.random.choice(TRAIN_SIZE, size=TRAIN_SIZE, replace=False)\n",
    "x_partition_train, x_sequence_train, x_term_train, x_masks_train, y_train = x_partition_data[train_shuffle], x_sequence_positions[train_shuffle], x_term_positions[train_shuffle], x_masks[train_shuffle], y_data[train_shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_SIZE = 0\n",
    "with open('lr_validation_data.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "validation_dict = {i:{} for i in validation_groups}\n",
    "current_partition = '3'\n",
    "current_group = 3\n",
    "current_dictionary = validation_dict[3]\n",
    "all_partition_data, all_sequence_positions, all_term_positions, all_ground_truths, all_masks = [], [], [], [], []\n",
    "for line in lines:\n",
    "    line_first_partition = line.split('  ')[0]\n",
    "    if line_first_partition != current_partition:\n",
    "        x_partition_data = torch.tensor(all_partition_data)\n",
    "        x_sequence_positions = torch.tensor(all_sequence_positions)\n",
    "        x_term_positions = torch.tensor(all_term_positions)\n",
    "        x_masks = torch.tensor(all_masks, dtype=float)\n",
    "        y_data = torch.tensor(all_ground_truths)\n",
    "        current_dictionary[current_partition] = (x_partition_data, x_sequence_positions, x_term_positions, x_masks, y_data)\n",
    "        line_first_digit = int(line_first_partition.split(' ')[0])\n",
    "        if line_first_digit > current_group:\n",
    "            current_group = line_first_digit\n",
    "            current_dictionary = validation_dict[current_group]\n",
    "        current_partition = line_first_partition\n",
    "        all_partition_data, all_sequence_positions, all_term_positions, all_ground_truths, all_masks = [], [], [], [], []\n",
    "    partition_data, sequence_positions, term_positions, ground_truth, mask = line_to_data(line)\n",
    "    if partition_data is not None:\n",
    "        all_partition_data.append(partition_data)\n",
    "        all_sequence_positions.append(sequence_positions)\n",
    "        all_term_positions.append(term_positions)\n",
    "        all_ground_truths.append(ground_truth)\n",
    "        all_masks.append(mask)\n",
    "        VAL_SIZE += 1\n",
    "x_partition_data = torch.tensor(all_partition_data)\n",
    "x_sequence_positions = torch.tensor(all_sequence_positions)\n",
    "x_term_positions = torch.tensor(all_term_positions)\n",
    "x_masks = torch.tensor(all_masks, dtype=float)\n",
    "y_data = torch.tensor(all_ground_truths)\n",
    "current_dictionary[current_partition] = (x_partition_data, x_sequence_positions, x_term_positions, x_masks, y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = KroneckerModel(num_tokens=MAX_PART_VALUE, input_embedding_dim=200, vector_dim=200, num_heads=10, num_layers=4, hidden_multiplier=1, dropout_prob=0.1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.95)\n",
    "\n",
    "model.train()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train accuracy: tensor(0.9157)\n",
      "2 1\n",
      "1 1 1\n",
      "3 tensor(0.8333)\n",
      "2 1 1 1\n",
      "1 1 1 1 1\n",
      "5 tensor(0.9351)\n",
      "6 1\n",
      "4 1 1 1\n",
      "2 1 1 1 1 1\n",
      "1 1 1 1 1 1 1\n",
      "7 tensor(0.9483)\n",
      "9\n",
      "8 1\n",
      "2 1 1 1 1 1 1 1\n",
      "1 1 1 1 1 1 1 1 1\n",
      "9 tensor(0.9656)\n",
      "11\n",
      "8 1 1 1\n",
      "7 1 1 1 1\n",
      "2 1 1 1 1 1 1 1 1 1\n",
      "11 tensor(0.9651)\n",
      "10 1 1 1\n",
      "13 tensor(0.9631)\n",
      "15 tensor(0.9593)\n",
      "Validation accuracy: tensor(0.9603)\n",
      "1\n",
      "Train accuracy: tensor(0.9629)\n",
      "3 tensor(0.8333)\n",
      "3 2\n",
      "3 1 1\n",
      "5 tensor(0.9481)\n",
      "7\n",
      "3 2 1 1\n",
      "3 1 1 1 1\n",
      "7 tensor(0.9775)\n",
      "7 2\n",
      "3 2 1 1 1 1\n",
      "9 tensor(0.9810)\n",
      "11 tensor(0.9805)\n",
      "13 tensor(0.9761)\n",
      "15 tensor(0.9689)\n",
      "Validation accuracy: tensor(0.9710)\n",
      "2\n",
      "Train accuracy: tensor(0.9787)\n",
      "3\n",
      "3 tensor(1.)\n",
      "2 2 1\n",
      "5 tensor(0.9740)\n",
      "5 2\n",
      "5 1 1\n",
      "4 2 1\n",
      "3 2 2\n",
      "2 2 2 1\n",
      "2 2 1 1 1\n",
      "7 tensor(0.9933)\n",
      "6 3\n",
      "6 2 1\n",
      "6 1 1 1\n",
      "5 2 2\n",
      "5 2 1 1\n",
      "5 1 1 1 1\n",
      "4 1 1 1 1 1\n",
      "3 2 2 2\n",
      "3 2 2 1 1\n",
      "3 1 1 1 1 1 1\n",
      "2 2 2 1 1 1\n",
      "2 2 1 1 1 1 1\n",
      "9 tensor(0.9960)\n",
      "10 1\n",
      "9 2\n",
      "8 2 1\n",
      "7 2 1 1\n",
      "6 3 1 1\n",
      "6 1 1 1 1 1\n",
      "5 1 1 1 1 1 1\n",
      "4 3 2 1 1\n",
      "3 2 2 2 1 1\n",
      "3 2 2 1 1 1 1\n",
      "3 1 1 1 1 1 1 1 1\n",
      "2 2 2 2 1 1 1\n",
      "2 2 2 1 1 1 1 1\n",
      "11 tensor(0.9946)\n",
      "12 1\n",
      "11 2\n",
      "11 1 1\n",
      "10 2 1\n",
      "9 2 1 1\n",
      "9 1 1 1 1\n",
      "8 1 1 1 1 1\n",
      "7 1 1 1 1 1 1\n",
      "6 1 1 1 1 1 1 1\n",
      "5 2 2 1 1 1 1\n",
      "2 2 2 1 1 1 1 1 1 1\n",
      "13 tensor(0.9924)\n",
      "12 1 1 1\n",
      "15 tensor(0.9878)\n",
      "Validation accuracy: tensor(0.9891)\n",
      "3\n",
      "Train accuracy: tensor(0.9863)\n",
      "3 tensor(1.)\n",
      "5\n",
      "4 1\n",
      "5 tensor(0.9935)\n",
      "3 3 1\n",
      "7 tensor(0.9917)\n",
      "7 1 1\n",
      "5 4\n",
      "4 3 2\n",
      "4 3 1 1\n",
      "4 2 2 1\n",
      "4 2 1 1 1\n",
      "3 3 1 1 1\n",
      "2 2 2 2 1\n",
      "9 tensor(0.9965)\n",
      "9 1 1\n",
      "7 3 1\n",
      "6 2 2 1\n",
      "6 2 1 1 1\n",
      "5 2 2 1 1\n",
      "5 2 1 1 1 1\n",
      "4 3 2 2\n",
      "4 2 2 1 1 1\n",
      "4 2 1 1 1 1 1\n",
      "4 1 1 1 1 1 1 1\n",
      "3 2 2 2 2\n",
      "3 2 1 1 1 1 1 1\n",
      "2 2 2 2 2 1\n",
      "11 tensor(0.9974)\n",
      "8 2 1 1 1\n",
      "7 3 1 1 1\n",
      "6 2 2 2 1\n",
      "6 2 2 1 1 1\n",
      "5 2 2 2 2\n",
      "13 tensor(0.9949)\n",
      "11 1 1 1 1\n",
      "15 tensor(0.9911)\n",
      "Validation accuracy: tensor(0.9922)\n",
      "4\n",
      "Train accuracy: tensor(0.9908)\n",
      "3 tensor(1.)\n",
      "5 tensor(0.9870)\n",
      "7 tensor(0.9933)\n",
      "3 3 2 1\n",
      "9 tensor(0.9972)\n",
      "8 3\n",
      "7 2 2\n",
      "5 2 2 2\n",
      "3 3 2 1 1 1\n",
      "3 3 1 1 1 1 1\n",
      "11 tensor(0.9953)\n",
      "9 2 2\n",
      "8 2 2 1\n",
      "7 2 2 2\n",
      "5 2 2 2 1 1\n",
      "13 tensor(0.9927)\n",
      "10 1 1 1 1 1\n",
      "9 2 2 2\n",
      "15 tensor(0.9890)\n",
      "Validation accuracy: tensor(0.9901)\n",
      "5\n",
      "Train accuracy: tensor(0.9936)\n",
      "3 tensor(1.)\n",
      "5 tensor(1.)\n",
      "4 3\n",
      "7 tensor(0.9967)\n",
      "4 4 1\n",
      "9 tensor(0.9983)\n",
      "6 4 1\n",
      "6 3 2\n",
      "5 4 2\n",
      "5 4 1 1\n",
      "5 3 2 1\n",
      "5 3 1 1 1\n",
      "4 4 2 1\n",
      "4 4 1 1 1\n",
      "4 3 3 1\n",
      "4 3 1 1 1 1\n",
      "4 2 2 2 1\n",
      "3 3 2 2 1\n",
      "11 tensor(0.9985)\n",
      "8 3 2\n",
      "7 3 2 1\n",
      "7 2 2 1 1\n",
      "6 3 2 1 1\n",
      "4 3 2 2 2\n",
      "4 2 2 2 2 1\n",
      "3 3 3 2 1 1\n",
      "3 2 2 2 1 1 1 1\n",
      "2 2 2 2 2 2 1\n",
      "2 2 2 2 2 1 1 1\n",
      "13 tensor(0.9969)\n",
      "12 2 1\n",
      "10 2 2 1\n",
      "10 2 1 1 1\n",
      "9 2 2 1 1\n",
      "9 2 1 1 1 1\n",
      "7 3 2 1 1 1\n",
      "15 tensor(0.9934)\n",
      "Validation accuracy: tensor(0.9944)\n",
      "6\n",
      "Train accuracy: tensor(0.9953)\n",
      "3 tensor(1.)\n",
      "5 tensor(1.)\n",
      "7 tensor(0.9992)\n",
      "5 3 1\n",
      "3 3 3\n",
      "9 tensor(1.)\n",
      "7 4\n",
      "3 3 3 1 1\n",
      "2 2 1 1 1 1 1 1 1\n",
      "11 tensor(0.9995)\n",
      "8 3 1 1\n",
      "7 4 2\n",
      "7 4 1 1\n",
      "7 2 1 1 1 1\n",
      "6 4 2 1\n",
      "6 3 2 2\n",
      "6 3 1 1 1 1\n",
      "6 2 1 1 1 1 1\n",
      "5 4 2 2\n",
      "5 3 2 2 1\n",
      "5 3 2 1 1 1\n",
      "5 3 1 1 1 1 1\n",
      "5 2 1 1 1 1 1 1\n",
      "5 1 1 1 1 1 1 1 1\n",
      "4 4 2 2 1\n",
      "4 3 2 2 1 1\n",
      "4 2 2 2 1 1 1\n",
      "4 2 2 1 1 1 1 1\n",
      "4 2 1 1 1 1 1 1 1\n",
      "4 1 1 1 1 1 1 1 1 1\n",
      "3 3 2 2 2 1\n",
      "3 3 2 2 1 1 1\n",
      "3 3 2 1 1 1 1 1\n",
      "3 3 1 1 1 1 1 1 1\n",
      "3 2 2 2 2 2\n",
      "3 2 2 1 1 1 1 1 1\n",
      "3 2 1 1 1 1 1 1 1 1\n",
      "2 2 2 2 1 1 1 1 1\n",
      "13 tensor(0.9989)\n",
      "11 2 1 1\n",
      "9 1 1 1 1 1 1\n",
      "8 2 2 2 1\n",
      "8 2 2 1 1 1\n",
      "8 2 1 1 1 1 1\n",
      "8 1 1 1 1 1 1 1\n",
      "7 3 1 1 1 1 1\n",
      "7 2 2 2 1 1\n",
      "7 2 2 1 1 1 1\n",
      "7 2 1 1 1 1 1 1\n",
      "7 1 1 1 1 1 1 1 1\n",
      "6 3 2 1 1 1 1\n",
      "6 2 2 2 2 1\n",
      "6 2 2 2 1 1 1\n",
      "6 2 2 1 1 1 1 1\n",
      "6 2 1 1 1 1 1 1 1\n",
      "6 1 1 1 1 1 1 1 1 1\n",
      "5 3 2 1 1 1 1 1\n",
      "5 2 2 2 1 1 1 1\n",
      "5 2 2 1 1 1 1 1 1\n",
      "5 2 1 1 1 1 1 1 1 1\n",
      "4 2 2 2 1 1 1 1 1\n",
      "3 2 2 2 1 1 1 1 1 1\n",
      "15 tensor(0.9970)\n",
      "Validation accuracy: tensor(0.9975)\n",
      "7\n",
      "Train accuracy: tensor(0.9963)\n",
      "3 tensor(1.)\n",
      "5 tensor(1.)\n",
      "7 tensor(0.9975)\n",
      "9 tensor(0.9997)\n",
      "5 3 3\n",
      "11 tensor(0.9993)\n",
      "8 4 1\n",
      "6 4 3\n",
      "5 4 2 1 1\n",
      "5 4 1 1 1 1\n",
      "4 4 1 1 1 1 1\n",
      "4 3 2 1 1 1 1\n",
      "3 3 3 1 1 1 1\n",
      "3 2 2 2 2 1 1\n",
      "13 tensor(0.9988)\n",
      "11 2 2\n",
      "8 4 2 1\n",
      "8 4 1 1 1\n",
      "15 tensor(0.9966)\n",
      "Validation accuracy: tensor(0.9972)\n",
      "8\n",
      "Train accuracy: tensor(0.9971)\n",
      "3 tensor(1.)\n",
      "5 tensor(1.)\n",
      "7 tensor(1.)\n",
      "9 tensor(0.9999)\n",
      "5 5 1\n",
      "11 tensor(0.9995)\n",
      "9 4\n",
      "9 3 1\n",
      "7 3 3\n",
      "6 6 1\n",
      "5 3 3 2\n",
      "4 4 2 1 1 1\n",
      "13 tensor(0.9989)\n",
      "9 3 3\n",
      "8 3 1 1 1 1\n",
      "15 tensor(0.9965)\n",
      "Validation accuracy: tensor(0.9971)\n",
      "9\n",
      "Train accuracy: tensor(0.9977)\n",
      "3 tensor(1.)\n",
      "5 tensor(1.)\n",
      "7 tensor(0.9992)\n",
      "9 tensor(0.9994)\n",
      "6 5\n",
      "11 tensor(0.9995)\n",
      "10 3\n",
      "7 6\n",
      "6 5 2\n",
      "5 3 3 1 1\n",
      "4 4 4 1\n",
      "13 tensor(0.9994)\n",
      "12 3\n",
      "11 4\n",
      "9 3 2 1\n",
      "8 3 2 2\n",
      "8 3 2 1 1\n",
      "7 6 2\n",
      "7 4 1 1 1 1\n",
      "7 2 2 2 2\n",
      "6 3 1 1 1 1 1 1\n",
      "5 3 1 1 1 1 1 1 1\n",
      "5 2 2 2 2 2\n",
      "4 3 2 1 1 1 1 1 1\n",
      "4 2 2 2 2 1 1 1\n",
      "4 2 2 1 1 1 1 1 1 1\n",
      "3 3 2 1 1 1 1 1 1 1\n",
      "2 2 2 2 2 1 1 1 1 1\n",
      "15 tensor(0.9979)\n",
      "Validation accuracy: tensor(0.9983)\n",
      "10\n",
      "Train accuracy: tensor(0.9981)\n",
      "3 tensor(0.8333)\n",
      "5 tensor(0.9935)\n",
      "7 tensor(1.)\n",
      "9 tensor(1.)\n",
      "11 tensor(0.9996)\n",
      "5 4 4\n",
      "4 3 3 1 1 1\n",
      "13 tensor(0.9991)\n",
      "11 3 1\n",
      "10 3 1 1\n",
      "9 3 1 1 1\n",
      "3 2 2 2 2 2 2\n",
      "2 2 2 2 2 2 2 1\n",
      "15 tensor(0.9974)\n",
      "Validation accuracy: tensor(0.9979)\n",
      "11\n",
      "Train accuracy: tensor(0.9985)\n",
      "3 tensor(1.)\n",
      "5 tensor(1.)\n",
      "7 tensor(1.)\n",
      "9 tensor(0.9997)\n",
      "11 tensor(0.9997)\n",
      "8 5\n",
      "6 4 1 1 1\n",
      "4 3 3 2 1\n",
      "4 3 1 1 1 1 1 1\n",
      "13 tensor(0.9996)\n",
      "10 3 2\n",
      "9 6\n",
      "8 3 3 1\n",
      "7 5 2 1\n",
      "7 3 2 2 1\n",
      "6 4 1 1 1 1 1\n",
      "6 3 2 2 1 1\n",
      "5 4 2 1 1 1 1\n",
      "5 4 1 1 1 1 1 1\n",
      "5 3 2 2 2 1\n",
      "5 3 2 2 1 1 1\n",
      "4 4 1 1 1 1 1 1 1\n",
      "4 3 3 2 1 1 1\n",
      "4 3 3 1 1 1 1 1\n",
      "4 3 2 2 1 1 1 1\n",
      "4 3 1 1 1 1 1 1 1 1\n",
      "3 3 2 2 2 2 1\n",
      "15 tensor(0.9987)\n",
      "Validation accuracy: tensor(0.9989)\n",
      "12\n",
      "Train accuracy: tensor(0.9987)\n",
      "3 tensor(1.)\n",
      "5 tensor(1.)\n",
      "7 tensor(1.)\n",
      "9 tensor(0.9999)\n",
      "4 4 3\n",
      "11 tensor(0.9999)\n",
      "5 5 2 1\n",
      "3 3 3 3 1\n",
      "13 tensor(0.9996)\n",
      "9 4 2\n",
      "7 4 2 1 1\n",
      "6 4 2 2 1\n",
      "5 2 2 2 2 1 1\n",
      "4 4 2 1 1 1 1 1\n",
      "3 3 2 2 1 1 1 1 1\n",
      "2 2 2 2 2 2 1 1 1\n",
      "15 tensor(0.9985)\n",
      "Validation accuracy: tensor(0.9988)\n",
      "13\n",
      "Train accuracy: tensor(0.9989)\n",
      "3 tensor(1.)\n",
      "5 tensor(1.)\n",
      "7 tensor(1.)\n",
      "9 tensor(0.9999)\n",
      "11 tensor(0.9999)\n",
      "5 4 3 1\n",
      "4 3 3 3\n",
      "13 tensor(0.9998)\n",
      "10 5\n",
      "9 5 1\n",
      "6 4 3 2\n",
      "5 4 3 2 1\n",
      "4 4 2 2 1 1 1\n",
      "4 2 2 2 2 2 1\n",
      "3 3 3 1 1 1 1 1 1\n",
      "15 tensor(0.9991)\n",
      "Validation accuracy: tensor(0.9993)\n",
      "14\n",
      "Train accuracy: tensor(0.9991)\n",
      "3 tensor(1.)\n",
      "5 tensor(1.)\n",
      "7 tensor(1.)\n",
      "9 tensor(1.)\n",
      "3 3 3 2\n",
      "11 tensor(1.)\n",
      "7 5 1\n",
      "6 5 1 1\n",
      "13 tensor(0.9997)\n",
      "10 4 1\n",
      "9 4 1 1\n",
      "7 5 1 1 1\n",
      "7 4 3 1\n",
      "6 3 2 2 2\n",
      "4 3 2 2 2 2\n",
      "3 2 2 2 2 2 1 1\n",
      "15 tensor(0.9986)\n",
      "Validation accuracy: tensor(0.9989)\n",
      "15\n",
      "Train accuracy: tensor(0.9993)\n",
      "3 tensor(1.)\n",
      "5 tensor(1.)\n",
      "7 tensor(1.)\n",
      "9 tensor(0.9997)\n",
      "11 tensor(0.9998)\n",
      "13 tensor(0.9998)\n",
      "8 4 3\n",
      "7 4 2 2\n",
      "7 3 3 2\n",
      "6 4 2 1 1 1\n",
      "6 3 3 1 1 1\n",
      "5 4 3 1 1 1\n",
      "5 4 2 2 1 1\n",
      "4 3 3 3 1 1\n",
      "4 3 3 2 2 1\n",
      "3 3 3 3 1 1 1\n",
      "3 3 3 2 2 1 1\n",
      "3 3 3 2 1 1 1 1\n",
      "3 3 2 2 2 1 1 1\n",
      "3 2 2 2 2 1 1 1 1\n",
      "15 tensor(0.9994)\n",
      "Validation accuracy: tensor(0.9995)\n",
      "16\n",
      "Train accuracy: tensor(0.9993)\n",
      "3 tensor(1.)\n",
      "5 tensor(1.)\n",
      "7 tensor(1.)\n",
      "9 tensor(0.9999)\n",
      "11 tensor(0.9999)\n",
      "6 3 3 1\n",
      "3 3 3 2 2\n",
      "13 tensor(0.9998)\n",
      "8 5 2\n",
      "6 5 1 1 1 1\n",
      "5 5 1 1 1 1 1\n",
      "15 tensor(0.9993)\n",
      "Validation accuracy: tensor(0.9994)\n",
      "17\n",
      "Train accuracy: tensor(0.9993)\n",
      "3 tensor(1.)\n",
      "5 tensor(1.)\n",
      "7 tensor(1.)\n",
      "9 tensor(1.)\n",
      "11 tensor(0.9999)\n",
      "13 tensor(0.9998)\n",
      "6 6 2 1\n",
      "15 tensor(0.9990)\n",
      "Validation accuracy: tensor(0.9992)\n",
      "18\n",
      "Train accuracy: tensor(0.9995)\n",
      "3 tensor(1.)\n",
      "5 tensor(1.)\n",
      "7 tensor(1.)\n",
      "9 tensor(1.)\n",
      "11 tensor(1.0000)\n",
      "5 5 1 1 1\n",
      "4 4 3 1 1\n",
      "13 tensor(0.9999)\n",
      "7 6 1 1\n",
      "7 5 3\n",
      "6 6 1 1 1\n",
      "6 5 2 1 1\n",
      "6 3 3 2 1\n",
      "5 3 3 1 1 1 1\n",
      "4 4 3 2 1 1\n",
      "4 3 2 2 2 1 1\n",
      "3 3 3 3 2 1\n",
      "15 tensor(0.9996)\n",
      "Validation accuracy: tensor(0.9997)\n",
      "19\n",
      "Train accuracy: tensor(0.9995)\n",
      "3 tensor(1.)\n",
      "5 tensor(1.)\n",
      "7 tensor(1.)\n",
      "9 tensor(1.)\n",
      "11 tensor(1.)\n",
      "13 tensor(0.9999)\n",
      "6 3 3 3\n",
      "5 3 3 3 1\n",
      "15 tensor(0.9996)\n",
      "Validation accuracy: tensor(0.9997)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "stats = []\n",
    "val_stats = []\n",
    "solved_partitions = []\n",
    "for i in range(0, num_epochs):\n",
    "    print(i)\n",
    "    total_acc = 0\n",
    "    temp_acc = 0\n",
    "    for run, j in enumerate(range(0, TRAIN_SIZE, batch_size)):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x_partition_train[j:j + batch_size], x_sequence_train[j:j + batch_size], x_term_train[j:j + batch_size], x_masks_train[j:j + batch_size])\n",
    "        sigmoid = nn.Sigmoid()\n",
    "        loss_function = nn.BCELoss()\n",
    "        out = sigmoid(out.mean(axis=1).squeeze(1))\n",
    "        loss = loss_function(out.to(torch.float32), y_train[j:j + batch_size].to(torch.float32))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        batch_acc = sum(torch.logical_and(out > 0.5, y_train[j:j + batch_size] == 1)) + sum(torch.logical_and(out< 0.5, y_train[j:j + batch_size] == 0))\n",
    "        total_acc += batch_acc\n",
    "        temp_acc += batch_acc\n",
    "    print(\"Train accuracy:\", total_acc/TRAIN_SIZE)\n",
    "    stats.append(total_acc/TRAIN_SIZE)\n",
    "    model.eval()\n",
    "    val_acc = 0.0\n",
    "    for group, group_dictionary in validation_dict.items():\n",
    "        group_acc = 0\n",
    "        group_items = 0\n",
    "        for partition, values in group_dictionary.items():\n",
    "            if values[0].shape[0] > 0:\n",
    "                num_items = values[0].shape[0]\n",
    "                partition_acc = 0\n",
    "                for j in range(0, num_items, batch_size):\n",
    "                    out = model(values[0][j:j+batch_size], values[1][j:j+batch_size], values[2][j:j+batch_size], values[3][j:j+batch_size])\n",
    "                    out = sigmoid(out.mean(axis=1).squeeze(1))\n",
    "                    partition_acc += sum(torch.logical_and(out > 0.5, values[4][j:j+batch_size] == 1)) + sum(torch.logical_and(out< 0.5, values[4][j:j+batch_size] == 0))\n",
    "                if partition_acc == num_items and partition not in solved_partitions:\n",
    "                    print(partition)\n",
    "                    solved_partitions.append(partition)\n",
    "                group_items += num_items\n",
    "                group_acc += partition_acc\n",
    "        print(group, group_acc/group_items)\n",
    "        val_acc += group_acc\n",
    "    print(\"Validation accuracy:\", val_acc/VAL_SIZE)\n",
    "    val_stats.append(val_acc/VAL_SIZE)\n",
    "    torch.save(model.state_dict(), f\"{i}_lr_writeup_long_run.blob\")\n",
    "    model.train()\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8804)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "val_data_lr = [1-torch.sum(y_train)/y_train.shape[0]] + val_stats\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "plt.plot([i for i in range(0, 15)], val_data_lr[:15], label='littlewood-richardson')\n",
    "plt.plot([i for i in range(0, 15)], [1 for i in range(0, 15)], '--', alpha=0.5)\n",
    "plt.xticks([i for i in range(0, 15)])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.ylim(0.7, 1.0)\n",
    "plt.xlim(0, 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([394722])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.8804),\n",
       " tensor(0.9603),\n",
       " tensor(0.9710),\n",
       " tensor(0.9891),\n",
       " tensor(0.9922),\n",
       " tensor(0.9901),\n",
       " tensor(0.9944),\n",
       " tensor(0.9975),\n",
       " tensor(0.9972),\n",
       " tensor(0.9971),\n",
       " tensor(0.9983),\n",
       " tensor(0.9979),\n",
       " tensor(0.9989),\n",
       " tensor(0.9988),\n",
       " tensor(0.9993),\n",
       " tensor(0.9989),\n",
       " tensor(0.9995),\n",
       " tensor(0.9994),\n",
       " tensor(0.9992),\n",
       " tensor(0.9997),\n",
       " tensor(0.9997)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1-torch.sum(y_train)/y_train.shape[0]] + val_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
